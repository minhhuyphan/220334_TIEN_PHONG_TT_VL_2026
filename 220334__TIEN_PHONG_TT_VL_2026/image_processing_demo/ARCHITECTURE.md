# 3-Layer Image Compositing Architecture

## ðŸ“ Kiáº¿n trÃºc Tá»•ng quan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND LAYER                           â”‚
â”‚  - Web Interface (Flask + HTML/CSS/JS)                      â”‚
â”‚  - Upload UI, Preview, Download                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API LAYER (REST)                         â”‚
â”‚  - /api/remove-background                                  â”‚
â”‚  - /api/generate-background                                â”‚
â”‚  - /api/create-banner                                      â”‚
â”‚  - /api/files                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 PROCESSING LAYER                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ LayerCompositor        | Advanced Compositor         â”‚  â”‚
â”‚  â”‚ - create_background()  | - paste_product()           â”‚  â”‚
â”‚  â”‚ - create_product()     | - add_smart_text()          â”‚  â”‚
â”‚  â”‚ - composite_layers()   | - calculate_brightness()    â”‚  â”‚
â”‚  â”‚ - add_text_overlay()   | - get_optimal_text_color()  â”‚  â”‚
â”‚  â”‚ - save_result()        | - find_text_placement()     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              IMAGE PROCESSING LAYER                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Pillow (PIL)    â”‚ rembg        â”‚ numpy               â”‚   â”‚
â”‚  â”‚ - Image ops     â”‚ - Background â”‚ - Array operations  â”‚   â”‚
â”‚  â”‚ - ImageDraw     â”‚   removal    â”‚ - Brightness calc   â”‚   â”‚
â”‚  â”‚ - ImageFont     â”‚ - UÂ²-Net ML  â”‚                     â”‚   â”‚
â”‚  â”‚ - Color ops     â”‚ - ONNX model â”‚                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                AI/ML LAYER (External)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Stable Diffusion â”‚ rembg UÂ²-Net                       â”‚  â”‚
â”‚  â”‚ - Local WebUI    â”‚ - Pre-trained model                â”‚  â”‚
â”‚  â”‚ - Replicate API  â”‚ - Optimized inference              â”‚  â”‚
â”‚  â”‚ - Text â†’ Image   â”‚ - Background segmentation          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              STORAGE LAYER                                  â”‚
â”‚  - input/          (Product images, backgrounds)           â”‚
â”‚  - output/         (Final banners)                          â”‚
â”‚  - fonts/          (TTF font files)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸŽ¨ The 3-Layer Image Model

### Layer 1: Background (Ná»n)
```
Purpose:    Create aesthetic context and lighting
Technology: Generative AI (Stable Diffusion)
Input:      Text prompt (English)
Output:     background_layer.png (RGB)

Example:
  Prompt: "modern blue gradient, professional lighting"
  â†“
  AI generates background image
  â†“
  Output: 800x600 RGB image
```

**Advantages:**
- AI excels at creating natural, beautiful backgrounds
- No text needed = No text corruption
- Customizable via prompt

**How it works:**
```
Stable Diffusion (Text-to-Image)
Input: "modern blue gradient background"
  â†“
1. Tokenize prompt
2. CLIP encoding (convert text to embeddings)
3. Diffusion model (iterative denoising)
4. VAE decoder (embeddings â†’ image)
Output: 512x512 RGB image
  â†“
Resize to 800x600
```

---

### Layer 2: Product (Sáº£n pháº©m)
```
Purpose:    Extract product with transparent background
Technology: Machine Learning (UÂ²-Net, rembg)
Input:      product_original.jpg (with background)
Output:     product_layer.png (RGBA, transparent)

Example:
  Input:  Nike shoe on white background
  â†“
  rembg removes white background
  â†“
  Output: Nike shoe with transparent background
```

**Algorithm: UÂ²-Net (Salient Object Detection)**
```
Input image (3 channels: RGB)
  â†“
[Residual U-Blocks Ã— 6]
  â”œâ”€ Encoder: Downsample + Feature extraction
  â””â”€ Decoder: Upsample + Detail refinement
  â†“
Output: Binary mask (foreground/background)
  â†“
Multiply with original image
  â†“
Output: RGBA image (with alpha channel)
```

**Why this layer matters:**
- Isolates product without manual cutting
- Alpha channel enables smooth compositing
- Faster than manual editing
- Consistent results

---

### Layer 3: Text & Overlay (Chá»¯ & Há»a tiáº¿t)
```
Purpose:    Add Vietnamese text and visual effects
Technology: Traditional Image Processing (Pillow)
Input:      Text string (Vietnamese)
Output:     Final banner (RGB)

Example:
  Input: "Giáº£m 50%"
  â†“
  1. Load font (Roboto-Bold.ttf - Unicode support)
  2. Calculate text position (auto, centered)
  3. Measure brightness at that position
  4. Choose text color (black on light, white on dark)
  5. Draw shadow/outline for visibility
  6. Draw text
  â†“
  Output: Professional-looking banner
```

**Color Selection Algorithm:**
```python
def get_optimal_text_color(background_region):
    brightness = average_pixel_value(background_region)
    if brightness > 128:
        return (0, 0, 0)      # Black text on light bg
    else:
        return (255, 255, 255) # White text on dark bg
```

**Text Positioning Strategy:**
```
Priority positions:
1. Top center (most visible)
2. Bottom center (secondary)
3. Left middle (if top occupied)
4. Right middle (if left occupied)

Constraints:
- Don't overlap with product
- Maintain readable area
- Consider aspect ratio
```

---

## ðŸ“Š Data Flow: Step-by-Step

### Complete Pipeline Example

```
INPUT
  â”œâ”€ product.jpg (with background)
  â””â”€ "SiÃªu Sale 50%"

STEP 1: Remove Background (Layer 2)
  â”œâ”€ Load: product.jpg
  â”œâ”€ Process: rembg UÂ²-Net model
  â””â”€ Output: product_no_bg.png (RGBA)

STEP 2: Generate Background (Layer 1)
  â”œâ”€ Prompt: "modern blue gradient, sportswear"
  â”œâ”€ Model: Stable Diffusion
  â””â”€ Output: background.png (RGB, 800x600)

STEP 3: Composite Layers (Layer 1 + 2)
  â”œâ”€ Base: background.png
  â”œâ”€ Overlay: product_no_bg.png (centered)
  â”œâ”€ Method: PIL paste with alpha mask
  â””â”€ Output: composite.png (RGB, 800x600)

STEP 4: Add Text (Layer 3)
  â”œâ”€ Text: "SiÃªu Sale 50%"
  â”œâ”€ Font: Roboto-Bold.ttf (Unicode)
  â”œâ”€ Brightness: Calculate from composite
  â”œâ”€ Color: auto-select (black or white)
  â”œâ”€ Position: Top center
  â”œâ”€ Effect: Add shadow for visibility
  â””â”€ Output: final_banner.png (RGB, 800x600)

FINAL OUTPUT: Professional banner with:
  âœ… Beautiful AI-generated background
  âœ… Clean product isolation
  âœ… Perfect Vietnamese text
  âœ… Optimal color contrast
```

---

## ðŸ§® Mathematical Operations

### 1. Image Compositing (Blending)

```
For each pixel (x, y):
    C_final(x,y) = C_bg(x,y) * (1 - Î±) + C_fg(x,y) * Î±
    
Where:
  C_bg    = background color
  C_fg    = foreground (product) color
  Î±       = alpha channel (0 = transparent, 1 = opaque)
  
Example:
  Background: (100, 150, 200) - RGB
  Product:    (255, 0, 0) - Red
  Alpha:      0.8 - 80% opaque
  
  Result:
    R = 100 * (1-0.8) + 255 * 0.8 = 20 + 204 = 224
    G = 150 * (1-0.8) + 0 * 0.8 = 30 + 0 = 30
    B = 200 * (1-0.8) + 0 * 0.8 = 40 + 0 = 40
    
  C_final = (224, 30, 40)
```

### 2. Brightness Calculation

```
Grayscale = 0.299*R + 0.587*G + 0.114*B

Example:
  Pixel: (100, 150, 200)
  Brightness = 0.299*100 + 0.587*150 + 0.114*200
             = 29.9 + 88.05 + 22.8
             = 140.75 (relatively bright)
             
  Decision: Use dark text (0, 0, 0)
```

### 3. Font Rendering

```
TTF Font Rendering Pipeline:

1. Load .ttf file
   â†“
2. Rasterize to bitmap
   â”œâ”€ Font size
   â”œâ”€ DPI (dots per inch)
   â””â”€ Anti-aliasing
   â†“
3. Render glyphs
   â”œâ”€ Character: 'S' â†’ Glyph index
   â”œâ”€ Kerning: Adjust spacing
   â””â”€ Ligatures: Handle combinations
   â†“
4. Composite on image
   â”œâ”€ Position: (x, y)
   â”œâ”€ Color: RGB
   â””â”€ Blend with background
   â†“
Output: Rendered text on image
```

---

## ðŸ”— Module Dependencies

```
layer_compositing.py
â”œâ”€â”€ PIL.Image
â”œâ”€â”€ PIL.ImageDraw
â”œâ”€â”€ PIL.ImageFont
â””â”€â”€ pathlib.Path

background_removal.py
â”œâ”€â”€ PIL.Image
â”œâ”€â”€ rembg.remove, new_session
â””â”€â”€ pathlib.Path

advanced_compositing.py
â”œâ”€â”€ PIL.Image, ImageDraw, ImageFont
â”œâ”€â”€ numpy
â””â”€â”€ pathlib.Path

stable_diffusion_integration.py
â”œâ”€â”€ requests
â”œâ”€â”€ PIL.Image
â”œâ”€â”€ io.BytesIO
â”œâ”€â”€ base64
â”œâ”€â”€ replicate (optional)
â””â”€â”€ pathlib.Path

app.py (Flask API)
â”œâ”€â”€ flask
â”œâ”€â”€ werkzeug
â”œâ”€â”€ layer_compositing
â”œâ”€â”€ background_removal
â”œâ”€â”€ stable_diffusion_integration
â”œâ”€â”€ PIL.Image
â””â”€â”€ pathlib.Path
```

---

## ðŸš€ Performance Characteristics

### Processing Times (Approximate)

| Step | Operation | Time | Notes |
|------|-----------|------|-------|
| Layer 1 | Generate background (Replicate) | 5-10s | API call + queue |
| Layer 1 | Generate background (Local WebUI) | 20-60s | Depends on GPU |
| Layer 2 | Remove background (rembg) | 2-5s | CPU/GPU optimized |
| Layer 3 | Composite + text | <1s | Very fast |
| **Total** | Full pipeline | 7-65s | Depends on Layer 1 |

### Memory Usage

- Layer 1: AI model requires 4-8GB VRAM (if local)
- Layer 2: rembg model ~200MB RAM
- Layer 3: Pillow operations <50MB RAM
- **Total:** ~4-8GB (dominated by Layer 1 model)

### Output Quality

- Resolution: Up to 1024x1024 (Stable Diffusion limit)
- Format: PNG (supports transparency)
- Color depth: 8-bit per channel (RGB/RGBA)
- Compression: Lossless

---

## ðŸŽ¯ Design Patterns

### 1. Strategy Pattern (AI Model Selection)

```python
class StableDiffusionGenerator:
    def __init__(self, api_type="local"):
        self.strategy = self._create_strategy(api_type)
    
    def generate_background(self, prompt):
        return self.strategy.generate(prompt)
```

### 2. Facade Pattern (API Layer)

```python
@app.route('/api/create-banner', methods=['POST'])
def create_banner():
    # Hides complexity of 3 layers
    compositor = LayerCompositor()
    compositor.create_background(...)
    compositor.composite_layers(...)
    compositor.add_text_overlay(...)
    return json.response()
```

### 3. Template Method Pattern (Processing)

```python
class Compositor:
    def process(self):
        self.load_layers()
        self.validate_input()
        self.composite()
        self.finalize()
```

---

## ðŸ”’ Error Handling

```
Pipeline Error Handling:

INPUT
  â†“
TRY:
  â”œâ”€ Layer 1: Generate background
  â”‚   â””â”€ CATCH: API error â†’ Use solid color background
  â”œâ”€ Layer 2: Remove background
  â”‚   â””â”€ CATCH: rembg error â†’ Use original image
  â”œâ”€ Layer 3: Add text
  â”‚   â””â”€ CATCH: Font error â†’ Use default font
  â””â”€ SAVE: Write to disk
      â””â”€ CATCH: Disk error â†’ Raise exception

OUTPUT: Graceful fallback or error message
```

---

## ðŸ“ˆ Scalability Considerations

### Horizontal Scaling

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API 1   â”‚â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
             â”œâ”€â†’ Load Balancer â†’ Queue â†’ Worker Pool
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ API 2   â”‚â”€â”€â”¤
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ API N   â”‚â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Each worker handles one pipeline.
```

### Caching Strategy

```
Cache Layer 1 outputs:
  Key: SHA256(prompt)
  Value: Generated image
  TTL: 24 hours
  
  Benefit: Identical prompts reuse results
```

### Async Processing

```
Request â†’ Task Queue â†’ Worker Pool â†’ Result Storage
  â†“                                      â†“
Return job_id                    Return result via webhook
```

---

## ðŸŽ“ Advanced Topics

### 1. Stable Diffusion Fine-tuning

```python
# Custom model training (advanced)
def fine_tune_for_products():
    """
    Train SD on product images
    - LoRA (Low-Rank Adaptation)
    - Textual Inversion
    """
```

### 2. Advanced Text Layout

```python
# Multi-line text, rotation, effects
def advanced_text_rendering():
    """
    - Text wrapping
    - Rotation
    - Gradient fill
    - Outline
    - Shadow
    """
```

### 3. Batch Processing

```python
# Process 1000+ images
def batch_banner_generation():
    """
    - Parallel processing
    - GPU optimization
    - Memory pooling
    """
```

---

## ðŸ“š References

- [Stable Diffusion Paper](https://arxiv.org/abs/2112.10752)
- [UÂ²-Net: Going Deeper with Nested U-Structure](https://arxiv.org/abs/2005.09007)
- [Pillow Handbook](https://pillow.readthedocs.io/)
- [OpenAI CLIP](https://github.com/openai/CLIP)

---

**Document Version:** 1.0  
**Last Updated:** 2026-02-02  
**Audience:** Technical documentation for developers
